## 引言

人类的大脑拥有$10^{11}$个神经元 (neuron)，每个神经元包含树突和轴突两个部分与外界连接，通过它们神经元可以接受不同的输入，并产生相应的输出。无数个这样的神经元通过复杂的结构连接在一起，构成了地球上最高等的生物的大脑。

人脑最最重要的特点就是它能够学习、进化。神经网络模型通过模拟神经元工作的原理，希望能够得到一个可以学习进化的模型。它自1940年诞生以来，一路上的发展起起伏伏。神经网络以能够学习出复杂的回归和分类假设著称，但同时训练一个复杂的神经网络是一件非常困难的事情，它需要大量的训练数据、庞大的计算力和计算时间，除此之外训练还常易陷入局部最优导致得到的模型泛化能力不强。近十年，伴随着大数据的兴起和GPU并行计算的普及，深层神经网络作为一种强大的学习模型以一种新的姿态又重现开始受到人们的关注。

本章除了介绍经典人工神经网络模型之外，还介绍了训练所需的梯度下降算法和反向传播算法，以及训练时常遇到的过拟合问题和正则化方法。
