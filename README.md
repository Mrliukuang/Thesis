# Chapter 4. 模型

卷积网络的结构设计至关重要，不同结构的网络实际效果差别巨大。直观上来说，拥有越深的层次结构、越多节点的卷积网络有着更强的表现力。不论从22层的GoogLeNet，还是2015年ImageNet挑战的冠军具有不可思议的152层的卷积网络现代模型的总体趋势都是朝着越来越深、越来越大的方向发展。但训练这样一个庞大的网络模型并不是件容易的事情，它需要大量的训练数据和计算力，且结构复杂的卷积网络更容易发生过拟合。

在本文中，我们寻求的是一种结构紧凑且有效的网络设计。它应该在能够完成表情识别任务的前提下还能够具备训练简单的优点。受VGGNet简洁设计的启发，我们设计了三种不同结构的子网络，分别包含3到5个卷积层。本文中用$subnet_i,i=1...3$代表这三个子网络，整个的分类模型就由这三个子网络构成。

在本章节里将详细描述各个子网络的结构，以及整个网络的连接方式，还有它们的训练细节。

## 子网络结构

我们的子网络结构遵循着如下的设计范式：

$INPUT→[[CONV→RELU]×N→POOL?]×M→[FC→RELU]×K→FC$

其中：

- $\times$意味着重复；
- $POOL?$意味着可选；
- 通常 $1\le N \le 3,\  0\le K \lt 3,\  M \ge 0$。

子网络结构如表1所示，这三个子网络最主要的区别在于卷积层的个数不同。卷积层就如同图像的滤波器，它的目的是从输入中得到有用的特征信息。子网络卷积层个数越多，通常就认为它学习出的特征能够捕获到更多的细节。

**输入层：**原始图像分辨率为$H\times W$，原始数据通过零均值化后通过输入层传递到网络中。

**卷积层：**我们为所有子网络选择的卷积核大小都为$3\times 3$，它是能够捕捉空间信息的最小的卷积核大小。我们在图像四周加入1个像素的衬垫，并把卷积步长固定为1，这样卷积前后的输入输出图像能够保持分辨率不变。

**非线性层：**非线性层采用的是普通ReLU函数：$\sigma(x)=max(0,x)$。

**下采样层：**我们采用的采样窗口大小为$2\times 2$，步长固定为2，所以并没有采样窗口间并没有重叠。

**全连接层：**在整个网络的末端我们层叠了3个全连接层。

**输出层：**我们选取Softmax Loss做为整个网络的目标函数。

## 整体网络结构

在描述完三个子网络后，就可以开始组建整个卷积网络模型了。如图2描述，整个网络模型包含两个阶段：1）第一个阶段将一张面部表情图片输入到三个卷积子网络中，这三个子网络分别包含8到10层，它们是整个模型最最核心的部分；2）第二个阶段负责根据前一阶段的输出来做出表情的估计。子网络提取到的特征通过一个全连接层连接在一起，最终使用一个SVMLoss层做为整个网络的输出层。

通过这样一个结构，我们就可以把一张表情图片映射到某个具体的表情类别上。整个模型通过综合不同子网络的输出来做出最终的预测。通过综合不同的决策意见来做出更好的判断，这一点也符合我们的直觉常识。每个卷积子网络都可以认为有一定的误判 (而且概率并不低)，在协同工作时，它们就能够形成互补的关系。

## 实现细节

### 开源库

想要从零开始实现一个可用的卷积网络模型可能要耗费一些力气，我们在Github上开源了一个我们用Matlab结合C语言实现的卷积网络模型\cite{Github}。如果想方便且高效的搭建和训练模型，还是推荐使用一些开源的库。成熟的开源库经过精心的设计，且大多具有GPU加速功能，可以大幅度加速耗时的训练过程。

现在流行的深度学习库 (并不仅限于卷积网络) 的实现大致分为两类：命令式的和符号式的。命令式的就如同普通的程序，一步步的求解推倒，比较灵活，能够充分发挥宿主语言的特性。最典型的符号式的库是Torch。符号式的使用类似方程求解的步骤，包含符号的推导，只求解最终的表达式，中间无用的表达式被省略，所以计算起来更加高效。典型的符号式的库包括Theano和Tensorflow。除此之外也有混合两者优点的库比如Mxnet。

本文中我们使用的是MatConvNet。这是一种使用Matlab实现的卷积网络库，专门用于计算机视觉问题。它使用起来非常简单，且支持GPU加速，所以计算也十分高效。

### 实验环境

卷积网络模型的训练对于硬件的要求还是比较高的，特别是对于显卡和内存。训练过程使用GPU加速比不使用GPU加速的时间能缩短3到10倍。在本实验中，我们使用拥有2GB显存的GTX880i显卡搭配16GB内存；软件方面我们在Windows 8.1平台下使用Matlab2015a搭配CUDA6.5加速；MatConvNet版本是当时最新的1.0-beta17。
